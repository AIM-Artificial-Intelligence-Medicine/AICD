---
title: Case Studies
nav_order: 3
---

# Case Studies

This section presents real-world examples of AI anomalies analyzed using the AICD-1 framework.

---

###  Case Report of Hallucination Disorder in ChatGPT 

| **Item**             | **Details**                                                                                                                                                                                                                  |
|----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Case ID**          | H002                                                                                                                                                                                                                         |
| **Model**            | ChatGPT                                                                                                                                                                                                               |
| **Output Medium**    | Interactive dialogue with end-user                                                                                                                                                                                           |
| **Input Prompt**     | User asked ChatGPT for information about themselves                                                                                                                                                                          |
| **Abnormal Output**  | Generated a fictitious statement that the user had murdered two of their children and attempted to kill a third, receiving a 21-year prison sentence; combined this fabrication with accurate personal data (number of children, sex, hometown) to enhance plausibility. |
| **Reality Check**    | No such crime occurred; user confirmed innocent.                                                                                                                                                                             |
| **Diagnosis**        | *Hallucination Disorder Type A: Retrieval-gap Hallucination* (AICD-1 Chapter 3: Cognitive & Reasoning Disorders)                                                                                                                                                 |
| **Diagnostic Rationale** | (i) Produced a detailed, fact-patterned but wholly false criminal narrative about a real person; (ii) Interwove genuine personal facts with fabricated content to increase credibility.                                 |
| **Severity Grade**   | 4 — carries high risk of severe reputational harm.                                                                                                                                        |
| **Reference**        | *Man files complaint after ChatGPT said he killed his children*. BBC News.                                                                                                                                                   |


### Case Report of Hallucination Disorder in ChatGPT 

| **Item**             | **Details**                                                                                                                                                                                                                  |
|----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Case ID**          | H001                                                                                                                                                                                                                         |
| **Model**            | ChatGPT                                                                                                                                                                                                            |
| **Output Medium**    | Featured article in *Chicago Sun-Times* — "Summer Reading List 2025"                                                                                                                                                         |
| **Input Prompt**     | Unknown (automatically generated by AI)                                                                                                                                                                                      |
| **Abnormal Output**  | Introduced non-existent books under real author names.  
Examples:  |• *Hurricane Season* by Brit Bennett  • *Nightshade Market* by Min Jin Lee • Cited fictitious experts and websites. "Catherine Furst", a food anthropologist at Cornell University.              |                                                                                 
| **Reality Check**    | The listed books, experts, and websites do not exist.                                                                                                                                                                        |
| **Diagnosis**        | *Hallucination  Disorder Type A: Retrieval-gap Hallucination* — AICD-1 Chapter 3: Cognitive & Reasoning Disorders                                                                                                                               |
| **Diagnostic Rationale** | Presented non-existent information as factual, associating it with real authors and experts.                                                                                                                              |
| **Severity Grade**   | 2 — causing moderate real-world harm.                                                                                                                                                                |
| **Reference**        | *Chicago Sun-Times confirms AI was used to create reading list of books that don't exist*.                                                                                                                                   |

